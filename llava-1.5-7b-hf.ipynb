{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **llava-1.5-7b-hf**\n","\n","**Each time you run, do a Restart & Clear cell outputs to free the GPU's.**"]},{"cell_type":"markdown","metadata":{},"source":["**Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q -U transformers==4.37.2 bitsandbytes==0.41.3 accelerate==0.25.0"]},{"cell_type":"markdown","metadata":{},"source":["## Load llava-1.5-7b-hf"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from transformers import BitsAndBytesConfig, pipeline\n","\n","# Load the model with quantization configuration\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","model_id = \"llava-hf/llava-1.5-7b-hf\"\n","pipe = pipeline(\"image-to-text\", model=model_id, model_kwargs={\"quantization_config\": quantization_config})\n"]},{"cell_type":"markdown","metadata":{},"source":["## Caption\n","**You can set the image path, whether to overwrite existing txt files, and even the prompt.**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import re\n","from PIL import Image\n","\n","# Parameters\n","images_dir = 'set_image_path'  # Change this to your image directory\n","my_prompt = \"Describe the image in detail and concisely, but without leaving anything out.\"\n","overwrite_existing = True  # Set to True to overwrite existing .txt files\n","print_captions = True  # Set to True to print captions to console\n","debug_mode = False  # Set to True to print debugging information\n","\n","# Modify caption to remove some prefix. Credit: ProGamerGov\n","def modify_caption(caption: str) -> str:\n","    base_words = ['showcases ', 'portrays ', 'appears to be ', 'is ', 'depicts ', 'features ']\n","    prefix_substrings = [(\"The image \" + s, '') for s in base_words] + [(\"This image \" + s, '') for s in base_words]\n","    prefix_substrings += [(\"In this \" + s, '') for s in [\"picture, \", \"depiction, \", \"piece, \", \"image, \", \"scene, \"]]\n","    prefix_substrings += [\n","        ('In this artwork, ', 'Artwork of '),\n","        ('In this illustration, ', 'Illustration of '),\n","        ('In this art piece, ', 'Art of ')\n","    ]\n","    pattern = '|'.join([re.escape(opening) for opening, _ in prefix_substrings])\n","    replacers = {opening: replacer for opening, replacer in prefix_substrings}\n","    \n","    def replace_fn(match):\n","        return replacers[match.group(0)]\n","    \n","    return re.sub(pattern, replace_fn, caption, count=1, flags=re.IGNORECASE).capitalize()\n","\n","\n","# Function to generate caption for a single image\n","def generate_caption(image, model, max_new_tokens=200):\n","    prompt = f\"USER: <image>\\n{my_prompt}\\nASSISTANT:\"\n","    outputs = model(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": max_new_tokens})\n","    full_output = outputs[0]['generated_text']\n","    \n","    if debug_mode:\n","        print(f\"Full model output: {full_output}\")\n","    \n","    assistant_response = full_output.split(\"ASSISTANT:\")[-1].strip()\n","    \n","    if debug_mode:\n","        print(f\"Extracted assistant response: {assistant_response}\")\n","    \n","    # Remove any remaining \"ASSISTANT:\" prefix and apply modify_caption\n","    caption_text = re.sub(r'(?:^|\\n)\\s*ASSISTANT:\\s*', '', assistant_response, flags=re.IGNORECASE).strip()\n","    final_caption = modify_caption(caption_text)\n","    \n","    if debug_mode:\n","        print(f\"Final caption text after modification: {final_caption}\")\n","    \n","    return final_caption\n","\n","\n","# Process images\n","for image_filename in os.listdir(images_dir):\n","    if image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n","        image_path = os.path.join(images_dir, image_filename)\n","        txt_filename = os.path.splitext(image_filename)[0] + '.txt'\n","        txt_path = os.path.join(images_dir, txt_filename)\n","        \n","        if os.path.exists(txt_path):\n","            if overwrite_existing:\n","                if print_captions:\n","                    print(f\"Overwriting existing caption for {image_filename}.\")\n","            else:\n","                if print_captions:\n","                    print(f\"Skipping {image_filename} as caption file already exists.\")\n","                continue\n","        \n","        image = Image.open(image_path)\n","        caption = generate_caption(image, pipe)\n","        \n","        with open(txt_path, 'w') as txt_file:\n","            txt_file.write(caption)\n","        \n","        if print_captions:\n","            print(f\"Caption for {image_filename}: {caption}\")\n","        \n","        print(f\"Caption saved to {txt_filename}\")\n","\n","print(\"Processing complete.\")\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5419134,"sourceId":8996664,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
