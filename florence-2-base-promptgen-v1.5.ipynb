{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Florence-2-base-PromptGen-v1.5**","metadata":{}},{"cell_type":"markdown","source":"**Dependencies**","metadata":{}},{"cell_type":"code","source":"!pip install -q -U git+https://github.com/huggingface/transformers bitsandbytes accelerate flash_attn einops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Florence-2-base-PromptGen-v1.5\nLoad only one time","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoProcessor\n\n# Load the model and processor\nmodel_id = \"MiaoshouAI/Florence-2-base-PromptGen-v1.5\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)\nprocessor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n\n# Set up device (if CUDA is available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Caption\n**You can set the image path, whether to overwrite existing txt files, and even the prompt.**","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nfrom PIL import Image\n\n# Parameters\n\n# Set the variable path to the source directory\nsource_path = '/kaggle/input/x'  # Update this to the path where your images are located\n\nimages_dir = '/kaggle/working/x'  # Change this to your image directory\n\n# Create the destination directory if it doesn't exist\nos.makedirs(images_dir, exist_ok=True)\n\n# Copy image files from source_path to images_dir\nfor file_name in os.listdir(source_path):\n    if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n        full_file_name = os.path.join(source_path, file_name)\n        if os.path.isfile(full_file_name):\n            shutil.copy(full_file_name, images_dir)\n\nmy_prompt = \"Describe the image in detail and concisely, but without leaving anything out.\"\n# prompt = \"<MORE_DETAILED_CAPTION>\"\noverwrite_existing = True  # Set to True to overwrite existing .txt files\nprint_captions = True  # Set to True to print captions to console\ndebug_mode = False  # Set to True to print debugging information\n\n# Function to generate caption for a single image\ndef generate_caption(image, model, processor, prompt, max_new_tokens=1024):\n    # Convert image to RGB to ensure compatibility\n    image = image.convert(\"RGB\")\n    \n    # Process the image and prompt\n    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n    generated_ids = model.generate(\n        input_ids=inputs[\"input_ids\"],\n        pixel_values=inputs[\"pixel_values\"],\n        max_new_tokens=max_new_tokens,\n        do_sample=False,\n        num_beams=3\n    )\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n    parsed_answer = processor.post_process_generation(generated_text, task=prompt, image_size=(image.width, image.height))\n    \n    if debug_mode:\n        print(f\"Full model output: {generated_text}\")\n        print(f\"Parsed answer: {parsed_answer}\")\n\n    # Extract the caption text from the dictionary\n    caption = parsed_answer.get(prompt, \"\")\n    \n    return caption\n\n# Process images\nfor image_filename in os.listdir(images_dir):\n    if image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n        image_path = os.path.join(images_dir, image_filename)\n        txt_filename = os.path.splitext(image_filename)[0] + '.txt'\n        txt_path = os.path.join(images_dir, txt_filename)\n        \n        if os.path.exists(txt_path):\n            if overwrite_existing:\n                if print_captions:\n                    print(f\"Overwriting existing caption for {image_filename}.\")\n            else:\n                if print_captions:\n                    print(f\"Skipping {image_filename} as caption file already exists.\")\n                continue\n        \n        image = Image.open(image_path)\n        caption = generate_caption(image, model, processor, my_prompt)\n        \n        with open(txt_path, 'w') as txt_file:\n            txt_file.write(caption)\n        \n        if print_captions:\n            print(f\"Caption for {image_filename}: {caption}\")\n        \n        print(f\"Caption saved to {txt_filename}\")\n\nprint(\"Processing complete.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# zip the output","metadata":{}},{"cell_type":"code","source":"!zip -r x.zip /kaggle/working/x","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}